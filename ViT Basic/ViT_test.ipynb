{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9750ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyViT import ViT\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a3952",
   "metadata": {},
   "source": [
    "### **无representation_size，无distilled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45bdd2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000])\n"
     ]
    }
   ],
   "source": [
    "vit_base = ViT(\n",
    "    img_size=224,\n",
    "    patchsize=16,\n",
    "    in_channels=3,\n",
    "    num_classes=1000,\n",
    "    embed_dim=768,\n",
    "    depth=12,\n",
    "    num_heads=12,\n",
    "    mlp_ratio=4,\n",
    "    qkv_bias=True,\n",
    "    representation_size=None,  \n",
    "    distilled=False,          \n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "x = torch.randn(1, 3, 224, 224)  # 示例输入\n",
    "inputs = torch.cat((x,x), dim=0)  # 模拟batch size为2的输入\n",
    "vit_base.eval()  \n",
    "output = vit_base(inputs)\n",
    "print(output.shape)  # torch.Size([1, 1000]) - 直接从cls_token分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e7f2c5",
   "metadata": {},
   "source": [
    "### **representation_size但不带distilled的ViT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "775db1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "# 在分类前添加额外投影头的ViT\n",
    "vit_with_rep = ViT(\n",
    "    img_size=224,\n",
    "    patchsize=16,\n",
    "    in_channels=3,\n",
    "    num_classes=1000,\n",
    "    embed_dim=768,\n",
    "    depth=12,\n",
    "    num_heads=12,\n",
    "    mlp_ratio=4,\n",
    "    qkv_bias=True,\n",
    "    representation_size=512,  # 添加投影头\n",
    "    distilled=False,          # 无蒸馏token\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# 前向传播：\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "output = vit_with_rep(x)\n",
    "print(output.shape)  # torch.Size([1, 1000]) \n",
    "# 内部会经过768->512的投影再进行最终分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591f0b4",
   "metadata": {},
   "source": [
    "### **带distilled但不带representation_size的ViT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec4c290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([1, 1000]) torch.Size([1, 1000])\n",
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "# 带蒸馏token的ViT(类似DeiT)\n",
    "vit_distilled = ViT(\n",
    "    img_size=224,\n",
    "    patchsize=16,\n",
    "    in_channels=3,\n",
    "    num_classes=1000,\n",
    "    embed_dim=768,\n",
    "    depth=12,\n",
    "    num_heads=12,\n",
    "    mlp_ratio=4,\n",
    "    qkv_bias=True,\n",
    "    representation_size=None,  # 无投影头\n",
    "    distilled=True,           # 使用蒸馏token\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# 前向传播：\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "output = vit_distilled(x)\n",
    "# 训练模式下返回(cls_logits, dist_logits)元组\n",
    "vit_distilled.train()\n",
    "train_output = vit_distilled(x)\n",
    "print(len(train_output))  # 2 - cls和dist两个输出\n",
    "print(train_output[0].shape, train_output[1].shape)  # torch.Size([1, 1000]), torch.Size([1, 1000])\n",
    "\n",
    "# 评估模式下返回两者的平均值\n",
    "vit_distilled.eval()\n",
    "eval_output = vit_distilled(x)\n",
    "print(eval_output.shape)  # torch.Size([1, 1000]) - 两个头的平均值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cbdde9",
   "metadata": {},
   "source": [
    "### **同时带representation_size和distilled的ViT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8688bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([1, 1000]) torch.Size([1, 1000])\n",
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "# 同时带投影头和蒸馏token的ViT\n",
    "vit_full = ViT(\n",
    "    img_size=224,\n",
    "    patchsize=16,\n",
    "    in_channels=3,\n",
    "    num_classes=1000,\n",
    "    embed_dim=768,\n",
    "    depth=12,\n",
    "    num_heads=12,\n",
    "    mlp_ratio=4,\n",
    "    qkv_bias=True,\n",
    "    representation_size=512,  # 添加投影头\n",
    "    distilled=True,          # 使用蒸馏token\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# 前向传播行为：\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "vit_full.train()\n",
    "train_output = vit_full(x)\n",
    "print(len(train_output))  # 2 - cls和dist两个输出\n",
    "print(train_output[0].shape, train_output[1].shape)  # 都是torch.Size([1, 1000])\n",
    "\n",
    "vit_full.eval()\n",
    "eval_output = vit_full(x)\n",
    "print(eval_output.shape)  # torch.Size([1, 1000]) - 平均值"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
