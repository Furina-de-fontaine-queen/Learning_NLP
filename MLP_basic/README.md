# MLP 手写数字识别项目

## 项目概述

本项目实现了一个基于多层感知机(MLP)的手写数字识别系统，使用PyTorch框架在MNIST数据集上进行训练和评估。

## 文件结构

- `MLP_Test.ipynb`: 主测试文件，包含数据加载、模型训练和评估流程
- `MyMLP.py`: MLP模型实现
- `MyMLPTrainer.py`: 训练器实现

## 数学原理

### 1. 多层感知机(MLP)结构

MLP由多个全连接层组成，数学表达式为：

```
h₁ = GELU(W₁x + b₁)
h₂ = GELU(W₂h₁ + b₂)
y = W₃h₂ + b₃
```

其中：
- W₁, W₂, W₃ 是权重矩阵
- b₁, b₂, b₃ 是偏置向量
- GELU是激活函数

### 2. GELU激活函数

GELU (Gaussian Error Linear Unit) 定义为：
```
GELU(x) = xΦ(x)
```
其中Φ(x)是标准高斯分布的累积分布函数。

### 3. 交叉熵损失函数

用于分类任务的损失函数：
```
L = -∑ y_i log(p_i)
```
其中y_i是真实标签，p_i是预测概率。

### 4. 优化器 - Adam

Adam优化器结合了动量法和RMSProp的优点，更新规则为：
```
m_t = β₁m_{t-1} + (1-β₁)g_t
v_t = β₂v_{t-1} + (1-β₂)g_t²
m̂_t = m_t / (1-β₁^t)
v̂_t = v_t / (1-β₂^t)
θ_t = θ_{t-1} - α m̂_t / (√v̂_t + ε)
```

## 使用说明

### 1. 环境配置

确保安装以下依赖：
```bash
pip install torch torchvision tqdm
```

### 2. 训练模型

在`MLP_Test.ipynb`中执行以下步骤：

1. 加载MNIST数据集
2. 初始化MLP模型
3. 设置训练器参数
4. 开始训练

### 3. 模型参数

- 输入层: 784 (28x28) 神经元
- 隐藏层: 512 神经元
- 输出层: 10 神经元 (对应0-9数字)
- 学习率: 0.001
- 批量大小: 100
- 训练周期: 10

### 4. 评估指标

训练过程中会输出：
- 训练损失
- 训练准确率
- 验证损失
- 验证准确率

最终测试准确率可达约98%。

## 扩展建议

1. 尝试不同的隐藏层大小
2. 调整学习率和批量大小
3. 添加更多隐藏层
4. 使用不同的激活函数(如ReLU)
5. 实现学习率调度

## 注意事项

1. 确保有可用的GPU设备(cuda:0)
2. 首次运行会自动下载MNIST数据集
3. 训练过程会保存模型权重到`./weights`目录
